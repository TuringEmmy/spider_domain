1. 获取的响应内容分类
   结构化
```python
json_str
   		json模块
   		jsonpath模块
   		re模块
xml
   		lxml(xpath)
   		re
```
   非结构化

```python
html
		lxml(xpath)
		re
```

2. json模块

```python
json.dumps # python数据类型-->json_str
json.loads # json_str-->python数据类型
json.dump # python数据类型-->写入 类文件对象
json.load # 类文件对象 读取-->python数据类型
```

2. jsonpath模块

```python
from jsonpath import jsonpath
jsonpath(python数据类型, '$..xx')
# 不管位置在哪，只要key是xx的值就放入list中并返回
# 如果取不到返回False
# 批量获取指定key的值！
```
4. 原始字符串r

```python
a = '\n' # 换行符
b = r'\n' # 此时仅表示\和n俩个字符，不再是换行符了
```

5. xpath语法

```python
//*[@id='xx']/..[2]/a[text()='xxx']//text()
		# id是xx的所有标签的父一级中第二个标签下文本内容是xxx的所有子级a标签下所有文本内容
	/html//div[last()-2]/./a/@href
		# html下所有div中倒数第三个下所有子级a标签的href属性的值
```

6. lxml模块的使用
```python
from lxml import etree
   html_element = etree.HTML(html_str)
   div_list = html_element.xpath('//div')
   for div in div_list:
   		href_list = div.xpath('./a/@href')
   # lxml.etree.HTML()能够修改html_str
   # lxml.etree.tostring()能够看到修改后的html_str
   # 爬虫要以修改的html_str为准进行提取数据！
```