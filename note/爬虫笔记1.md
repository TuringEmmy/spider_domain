### 一、爬虫的概念

网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟浏览器发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。



### 二、爬虫的流程

**爬虫的分类**

- 通用爬虫 ：通常指搜索引擎的爬虫（[https://www.baidu.com）](https://www.baidu.com）)
- 聚焦爬虫 ：针对特定网站的爬虫

![enter description here](./images/TuringEmmy201811181542506082.png "TuringEmmy201811181542506082")


- 向起始url发送请求，并获取响应
- 对响应进行提取
- 如果提取url，则继续发送请求获取响应
- 如果提取数据，则将数据进行保存

### 三、robots协议

> 在百度搜索中，不能搜索到淘宝网中某一个具体的商品的详情页面，这就是robots协议在起作用

Robots协议：网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取，但它仅仅是互联网中的一般约定

例如：[淘宝的robots协议](https://www.taobao.com/robots.txt)

### 四、http协议

| HTTP          | 超文本传输协议                | 80      |
| ------------- | ---------------------- | ------- |
| **HTTPS****** | **HTTP + SSL(安全套接字层)** | **443** |

**http请求的形式**

![enter description here](./images/TuringEmmy201811181542506295.png "TuringEmmy201811181542506295")



### 五、http请求头和响应头

| 请求头                              | 说明                     |
| -------------------------------- | ---------------------- |
| Host                             | 主机和端口号                 |
| Connection                       | 链接类型                   |
| Upgrade-Insecure-Requests        | 升级为HTTPS请求             |
| User-Agent                       | 浏览器名称                  |
| Accept                           | 传输文件类型                 |
| Referer                          | 页面跳转处                  |
| Accept-Encoding                  | 文件编解码格式                |
| Cookie                           | Cookie                 |
| x-requested-with :XMLHttpRequest | 表示该请求是Ajax异步请求         |
| **响应头**                          | **说明**                 |
| Set-Cookie                       | 对方服务器设置cookie到用户浏览器的缓存 |

**常见状态码**

| 状态码  | 说明             |
| ---- | -------------- |
| 200  | 成功             |
| 302  | 临时转移至新的url     |
| 307  | 临时转移至新的url     |
| 404  | 找不到该页面         |
| 500  | 服务器内部错误        |
| 503  | 服务器不可用，一般是被反爬虫 |

### 六、py3字符串整理

#### 字符，字符集

字符(Character)是各种文字和符号的总称

字符集包括：ASCII字符集、GB2312字符集、GB18030字符集、Unicode字符集等

#### python3中两种字符串类型：

- str : unicode的呈现形式
- bytes :字节类型，互联网上数据的都是以二进制的方式(字节类型)传输的

关于bytes的拓展阅读：[https://segmentfault.com/a/1190000004450876](https://segmentfault.com/a/1190000004450876)

#### str和byytes类型的相互转换

- str 使用encode方法转化为 bytes

  ```
  s = 'abc'
  print(type(s))
  #str编码变为bytes类型
  b = s.encode
  print(type(b))
  ```

- bytes 通过decode转化为 str

  ```
  b = b'abc'
  print(type(b))
  #bytes类型解码成为str类型
  s = b.decode()
  print(type(s))
  ```

### 七、requests模块发送简单请求获取响应以及常见属性

| 属性                | 说明                         |
| ----------------- | -------------------------- |
| `text`            | 响应体 str类型                  |
| `content`         | 响应体 bytes类型                |
| `status_code`     | 响应状态码                      |
| `request.headers` | 响应对应的请求头                   |
| `headers`         | 响应头                        |
| `request.cookies` | 响应对应请求的cookie              |
| `cookies`         | 响应的cookie（经过了set-cookie动作） |

### 八、保存图片到本地

- 图片的url: [https://www.baidu.com/img/bd_logo1.png](https://www.baidu.com/img/bd_logo1.png)
- 利用requests模块发送请求获取响应
- 以2进制写入的方式打开文件，并将response响应的二进制内容写入

```python
import requests

# 图片的url
url = 'https://www.baidu.com/img/bd_logo1.png' 

# 响应本身就是一个图片,并且是二进制类型
response = requests.get(url) 

# print(response.content)

# 以二进制+写入的方式打开文件
with open('baidu.png', 'wb') as f: 
    # 写入response.content bytes二进制类型
    f.write(response.content)
```